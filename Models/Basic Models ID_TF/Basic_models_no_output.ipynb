{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the training data\n",
    "train = pd.read_csv('https://github.com/tcastrom/CEFR-French-/raw/main/Data/training_data.csv')\n",
    "train.set_index('id', inplace=True)\n",
    "display(train.head())\n",
    "\n",
    "#Import the unlabel data\n",
    "unlabel = pd.read_csv('https://github.com/tcastrom/CEFR-French-/raw/main/Data/unlabelled_test_data.csv')\n",
    "unlabel.set_index('id', inplace=True)\n",
    "display(unlabel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the difficulty column using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['difficulty'] = le.fit_transform(train['difficulty'])\n",
    "\n",
    "# Display how the difficulty has been encoded and the values associated with each encoding\n",
    "display(le.classes_)\n",
    "print(f'The values [0, 1, 2, 3, 4, 5] are represented by{le.inverse_transform([0, 1, 2, 3, 4, 5])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y\n",
    "X = train['sentence']\n",
    "y = train['difficulty']\n",
    "\n",
    "# Split the data into train and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the vectorizer on the training data\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the vectorizer on the testing data\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a linear regression \n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predict the difficulty on the testing data\n",
    "y_pred = linear_regression.predict(X_test)\n",
    "\n",
    "# Round the predictions to the nearest integer and make sure the values are between 0 and 5\n",
    "y_pred = np.round(y_pred)\n",
    "y_pred[y_pred < 0] = 0\n",
    "y_pred[y_pred > 5] = 5\n",
    "\n",
    "# Reverse the encoding of the difficulty\n",
    "y_test_unencoded = le.inverse_transform(y_test)\n",
    "y_pred_unencoded = le.inverse_transform(y_pred.astype(int))\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_reg_lin = accuracy_score(y_test_unencoded, y_pred_unencoded)\n",
    "print(f'Accuracy: {accuracy_reg_lin}')\n",
    "\n",
    "# Calculate the Precision \n",
    "precision_reg_lin = precision_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Precision: {precision_reg_lin}')\n",
    "\n",
    "# Calculate the Recall\n",
    "recall_reg_lin = recall_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Recall: {recall_reg_lin}')\n",
    "\n",
    "# Calculate the F1 Score\n",
    "f1_reg_lin = f1_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'F1 Score: {f1_reg_lin}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic  Regression with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a logistic regression woth cross validation\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Create a logistic regression object\n",
    "logistic_regression = LogisticRegressionCV(cv=5, max_iter=1000)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predict the difficulty on the testing data\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Reverse the encoding of the difficulty\n",
    "y_test_unencoded = le.inverse_transform(y_test)\n",
    "y_pred_unencoded = le.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_log_reg = accuracy_score(y_test_unencoded, y_pred_unencoded)\n",
    "print(f'Accuracy: {accuracy_log_reg}')\n",
    "\n",
    "# Calculate the Precision\n",
    "precision_log_reg = precision_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Precision: {precision_log_reg}')\n",
    "\n",
    "# Calculate the Recall\n",
    "recall_log_reg = recall_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Recall: {recall_log_reg}')\n",
    "\n",
    "# Calculate the F1 Score\n",
    "f1_log_reg = f1_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'F1 Score: {f1_log_reg}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': range(1, 11),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_knn = GridSearchCV(estimator=knn, param_grid=param_grid_knn, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_knn = grid_search_knn.best_params_\n",
    "\n",
    "print(f\"The best parameters are : {best_params_knn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model\n",
    "best_model_knn = grid_search_knn.best_estimator_\n",
    "\n",
    "# Predict the difficulty on the testing data\n",
    "y_pred = best_model_knn.predict(X_test)\n",
    "\n",
    "# Reverse the encoding of the difficulty\n",
    "y_test_unencoded = le.inverse_transform(y_test)\n",
    "y_pred_unencoded = le.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_knn = accuracy_score(y_test_unencoded, y_pred_unencoded)\n",
    "print(f'Accuracy: {accuracy_knn}')\n",
    "\n",
    "# Calculate the Precision\n",
    "precision_knn = precision_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Precision: {precision_knn}')\n",
    "\n",
    "# Calculate the Recall\n",
    "recall_knn = recall_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Recall: {recall_knn}')\n",
    "\n",
    "# Calculate the F1 Score\n",
    "f1_knn = f1_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'F1 Score: {f1_knn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree with GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': range(1, 11),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_dt = GridSearchCV(estimator=dt, param_grid=param_grid_dt, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_dt = grid_search_dt.best_params_\n",
    "\n",
    "print(f\"The best parameters are : {best_params_dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model\n",
    "best_model_dt = grid_search_dt.best_estimator_\n",
    "\n",
    "# Predict the difficulty on the testing data\n",
    "y_pred = best_model_dt.predict(X_test)\n",
    "\n",
    "# Reverse the encoding of the difficulty\n",
    "y_test_unencoded = le.inverse_transform(y_test)\n",
    "y_pred_unencoded = le.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_dt = accuracy_score(y_test_unencoded, y_pred_unencoded)\n",
    "print(f'Accuracy: {accuracy_dt}')\n",
    "\n",
    "# Calculate the Precision\n",
    "precision_dt = precision_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Precision: {precision_dt}')\n",
    "\n",
    "# Calculate the Recall\n",
    "recall_dt = recall_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Recall: {recall_dt}')\n",
    "\n",
    "# Calculate the F1 Score\n",
    "f1_dt = f1_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'F1 Score: {f1_dt}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest with GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(1, 11),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(f\"The best parameters are : {best_params_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model\n",
    "best_model_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Predict the difficulty on the testing data\n",
    "y_pred = best_model_rf.predict(X_test)\n",
    "\n",
    "# Reverse the encoding of the difficulty\n",
    "y_test_unencoded = le.inverse_transform(y_test)\n",
    "y_pred_unencoded = le.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_rf = accuracy_score(y_test_unencoded, y_pred_unencoded)\n",
    "print(f'Accuracy: {accuracy_rf}')\n",
    "\n",
    "# Calculate the Precision\n",
    "precision_rf = precision_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Precision: {precision_rf}')\n",
    "\n",
    "# Calculate the Recall\n",
    "recall_rf = recall_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Recall: {recall_rf}')\n",
    "\n",
    "# Calculate the F1 Score\n",
    "f1_rf = f1_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'F1 Score: {f1_rf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suport Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine with GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "svm = SVC()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_svm = GridSearchCV(estimator=svm, param_grid=param_grid_svm, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "print(f\"The best parameters are : {best_params_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model\n",
    "best_model_svm = grid_search_svm.best_estimator_\n",
    "\n",
    "# Predict the difficulty on the testing data\n",
    "y_pred = best_model_svm.predict(X_test)\n",
    "\n",
    "# Reverse the encoding of the difficulty\n",
    "y_test_unencoded = le.inverse_transform(y_test)\n",
    "y_pred_unencoded = le.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_svm = accuracy_score(y_test_unencoded, y_pred_unencoded)\n",
    "print(f'Accuracy: {accuracy_svm}')\n",
    "\n",
    "# Calculate the Precision\n",
    "precision_svm = precision_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Precision: {precision_svm}')\n",
    "\n",
    "# Calculate the Recall\n",
    "recall_svm = recall_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Recall: {recall_svm}')\n",
    "\n",
    "# Calculate the F1 Score\n",
    "f1_svm = f1_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'F1 Score: {f1_svm}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_nb = {\n",
    "    'alpha': [0.1, 1, 10],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_nb = GridSearchCV(estimator=nb, param_grid=param_grid_nb, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_nb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_nb = grid_search_nb.best_params_\n",
    "print(f\"The best parameters are : {best_params_nb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model\n",
    "best_model_nb = grid_search_nb.best_estimator_\n",
    "\n",
    "# Predict the difficulty on the testing data\n",
    "y_pred = best_model_nb.predict(X_test)\n",
    "\n",
    "# Reverse the encoding of the difficulty\n",
    "y_test_unencoded = le.inverse_transform(y_test)\n",
    "y_pred_unencoded = le.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_nb = accuracy_score(y_test_unencoded, y_pred_unencoded)\n",
    "print(f'Accuracy: {accuracy_nb}')\n",
    "\n",
    "# Calculate the Precision\n",
    "precision_nb = precision_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Precision: {precision_nb}')\n",
    "\n",
    "# Calculate the Recall\n",
    "recall_nb = recall_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Recall: {recall_nb}')\n",
    "\n",
    "# Calculate the F1 Score\n",
    "f1_nb = f1_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'F1 Score: {f1_nb}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent with GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_sgd = {\n",
    "    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter': [1000, 2000, 5000]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_sgd = GridSearchCV(estimator=sgd, param_grid=param_grid_sgd, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_sgd.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_sgd = grid_search_sgd.best_params_\n",
    "print(f\"The best parameters are : {best_params_sgd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model\n",
    "best_model_sgd = grid_search_sgd.best_estimator_\n",
    "\n",
    "# Predict the difficulty on the testing data\n",
    "y_pred = best_model_sgd.predict(X_test)\n",
    "\n",
    "# Reverse the encoding of the difficulty\n",
    "y_test_unencoded = le.inverse_transform(y_test)\n",
    "y_pred_unencoded = le.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_sgd = accuracy_score(y_test_unencoded, y_pred_unencoded)\n",
    "print(f'Accuracy: {accuracy_sgd}')\n",
    "\n",
    "# Calculate the Precision\n",
    "precision_sgd = precision_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Precision: {precision_sgd}')\n",
    "\n",
    "# Calculate the Recall\n",
    "recall_sgd = recall_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Recall: {recall_sgd}')\n",
    "\n",
    "# Calculate the F1 Score\n",
    "f1_sgd = f1_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'F1 Score: {f1_sgd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Machines (GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting with GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'max_depth': range(1, 11),\n",
    "    'subsample': [0.5, 0.75, 1],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_gb = GridSearchCV(estimator=gb, param_grid=param_grid_gb, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_gb = grid_search_gb.best_params_\n",
    "print(f\"The best parameters are : {best_params_gb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model\n",
    "best_model_gb = grid_search_gb.best_estimator_\n",
    "\n",
    "# Predict the difficulty on the testing data\n",
    "y_pred = best_model_gb.predict(X_test)\n",
    "\n",
    "# Reverse the encoding of the difficulty\n",
    "y_test_unencoded = le.inverse_transform(y_test)\n",
    "y_pred_unencoded = le.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_gb = accuracy_score(y_test_unencoded, y_pred_unencoded)\n",
    "print(f'Accuracy: {accuracy_gb}')\n",
    "\n",
    "# Calculate the Precision\n",
    "precision_gb = precision_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Precision: {precision_gb}')\n",
    "\n",
    "# Calculate the Recall\n",
    "recall_gb = recall_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Recall: {recall_gb}')\n",
    "\n",
    "# Calculate the F1 Score\n",
    "f1_gb = f1_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'F1 Score: {f1_gb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost with GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_ab = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "ab = AdaBoostClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_ab = GridSearchCV(estimator=ab, param_grid=param_grid_ab, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_ab.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_ab = grid_search_ab.best_params_\n",
    "print(f\"The best parameters are : {best_params_ab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model\n",
    "best_model_ab = grid_search_ab.best_estimator_\n",
    "\n",
    "# Predict the difficulty on the testing data\n",
    "y_pred = best_model_ab.predict(X_test)\n",
    "\n",
    "# Reverse the encoding of the difficulty\n",
    "y_test_unencoded = le.inverse_transform(y_test)\n",
    "y_pred_unencoded = le.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_ab = accuracy_score(y_test_unencoded, y_pred_unencoded)\n",
    "print(f'Accuracy: {accuracy_ab}')\n",
    "\n",
    "# Calculate the Precision\n",
    "precision_ab = precision_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Precision: {precision_ab}')\n",
    "\n",
    "# Calculate the Recall\n",
    "recall_ab = recall_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Recall: {recall_ab}')\n",
    "\n",
    "# Calculate the F1 Score\n",
    "f1_ab = f1_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'F1 Score: {f1_ab}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Discriminant Analysis (QDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic Discriminant Analysis with GridSearchCV\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid_qda = {\n",
    "    'reg_param': [0.0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_qda = GridSearchCV(estimator=qda, param_grid=param_grid_qda, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_qda.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_qda = grid_search_qda.best_params_\n",
    "print(f\"The best parameters are : {best_params_qda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model\n",
    "best_model_qda = grid_search_qda.best_estimator_\n",
    "\n",
    "# Predict the difficulty on the testing data\n",
    "y_pred = best_model_qda.predict(X_test.toarray())\n",
    "\n",
    "# Reverse the encoding of the difficulty\n",
    "y_test_unencoded = le.inverse_transform(y_test)\n",
    "y_pred_unencoded = le.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_qda = accuracy_score(y_test_unencoded, y_pred_unencoded)\n",
    "print(f'Accuracy: {accuracy_qda}')\n",
    "\n",
    "# Calculate the Precision\n",
    "precision_qda = precision_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Precision: {precision_qda}')\n",
    "\n",
    "# Calculate the Recall\n",
    "recall_qda = recall_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'Recall: {recall_qda}')\n",
    "\n",
    "# Calculate the F1 Score\n",
    "f1_qda = f1_score(y_test_unencoded, y_pred_unencoded, average='weighted')\n",
    "print(f'F1 Score: {f1_qda}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all the results into a Table. The columns are : Model, Accuracy, Precision, Recall, F1 Score \n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Logistic Regression', 'K-Nearest Neighbors', 'Decision Tree', 'Random Forest', 'Support Vector Machine', 'Naive Bayes', 'Stochastic Gradient Descent', 'Gradient Boosting', 'AdaBoost', 'Quadratic Discriminant Analysis'],\n",
    "    'Accuracy': [accuracy_reg_lin, accuracy_log_reg, accuracy_knn, accuracy_dt, accuracy_rf, accuracy_svm, accuracy_nb, accuracy_sgd, accuracy_gb, accuracy_ab, accuracy_qda],\n",
    "    'Precision': [precision_reg_lin, precision_log_reg, precision_knn, precision_dt, precision_rf, precision_svm, precision_nb, precision_sgd, precision_gb, precision_ab, precision_qda],\n",
    "    'Recall': [recall_reg_lin, recall_log_reg, recall_knn, recall_dt, recall_rf, recall_svm, recall_nb, recall_sgd, recall_gb, recall_ab, recall_qda],\n",
    "    'F1 Score': [f1_reg_lin, f1_log_reg, f1_knn, f1_dt, f1_rf, f1_svm, f1_nb, f1_sgd, f1_gb, f1_ab, f1_qda]\n",
    "})\n",
    "\n",
    "#Round the values to 2 decimal places\n",
    "results = results.round(2)\n",
    "\n",
    "display(results)\n",
    "\n",
    "# Function to format numbers to 2 significant figures\n",
    "def format_sigfig(x):\n",
    "    if isinstance(x, float):\n",
    "        return '{:.2g}'.format(x)\n",
    "    return x\n",
    "\n",
    "# Apply formatting function to the DataFrame\n",
    "formatted_results = results.applymap(format_sigfig)\n",
    "\n",
    "\n",
    "# Use the .style attribute for better formatting\n",
    "styled_results = formatted_results.style.set_table_styles([\n",
    "    {'selector': 'thead th', 'props': [('background-color', 'grey'), ('color', 'black'), ('font-weight', 'bold')]},\n",
    "    {'selector': 'tbody tr:nth-child(even)', 'props': [('background-color', '#f2f2f2'),('color', 'black'), ('font-weight', 'bold')]},\n",
    "    {'selector': 'tbody tr:nth-child(odd)', 'props': [('background-color', 'white'),('color', 'black'), ('font-weight', 'bold')]}\n",
    "]).set_properties(**{'text-align': 'center'}).set_caption(\"Model Performance Comparison\")\n",
    "\n",
    "display(styled_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    "#T_f4a83 thead th {\n",
    "  background-color: grey;\n",
    "  color: black;\n",
    "  font-weight: bold;\n",
    "}\n",
    "#T_f4a83 tbody tr:nth-child(even) {\n",
    "  background-color: #f2f2f2;\n",
    "  color: black;\n",
    "  font-weight: bold;\n",
    "}\n",
    "#T_f4a83 tbody tr:nth-child(odd) {\n",
    "  background-color: white;\n",
    "  color: black;\n",
    "  font-weight: bold;\n",
    "}\n",
    "#T_f4a83_row0_col0, #T_f4a83_row0_col1, #T_f4a83_row0_col2, #T_f4a83_row0_col3, #T_f4a83_row0_col4, #T_f4a83_row1_col0, #T_f4a83_row1_col1, #T_f4a83_row1_col2, #T_f4a83_row1_col3, #T_f4a83_row1_col4, #T_f4a83_row2_col0, #T_f4a83_row2_col1, #T_f4a83_row2_col2, #T_f4a83_row2_col3, #T_f4a83_row2_col4, #T_f4a83_row3_col0, #T_f4a83_row3_col1, #T_f4a83_row3_col2, #T_f4a83_row3_col3, #T_f4a83_row3_col4, #T_f4a83_row4_col0, #T_f4a83_row4_col1, #T_f4a83_row4_col2, #T_f4a83_row4_col3, #T_f4a83_row4_col4, #T_f4a83_row5_col0, #T_f4a83_row5_col1, #T_f4a83_row5_col2, #T_f4a83_row5_col3, #T_f4a83_row5_col4, #T_f4a83_row6_col0, #T_f4a83_row6_col1, #T_f4a83_row6_col2, #T_f4a83_row6_col3, #T_f4a83_row6_col4, #T_f4a83_row7_col0, #T_f4a83_row7_col1, #T_f4a83_row7_col2, #T_f4a83_row7_col3, #T_f4a83_row7_col4, #T_f4a83_row8_col0, #T_f4a83_row8_col1, #T_f4a83_row8_col2, #T_f4a83_row8_col3, #T_f4a83_row8_col4, #T_f4a83_row9_col0, #T_f4a83_row9_col1, #T_f4a83_row9_col2, #T_f4a83_row9_col3, #T_f4a83_row9_col4, #T_f4a83_row10_col0, #T_f4a83_row10_col1, #T_f4a83_row10_col2, #T_f4a83_row10_col3, #T_f4a83_row10_col4 {\n",
    "  text-align: center;\n",
    "}\n",
    "</style>\n",
    "<table id=\"T_f4a83\">\n",
    "  <caption>Model Performance Comparison</caption>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th class=\"blank level0\" >&nbsp;</th>\n",
    "      <th id=\"T_f4a83_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
    "      <th id=\"T_f4a83_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
    "      <th id=\"T_f4a83_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
    "      <th id=\"T_f4a83_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
    "      <th id=\"T_f4a83_level0_col4\" class=\"col_heading level0 col4\" >F1 Score</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th id=\"T_f4a83_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
    "      <td id=\"T_f4a83_row0_col0\" class=\"data row0 col0\" >Linear Regression</td>\n",
    "      <td id=\"T_f4a83_row0_col1\" class=\"data row0 col1\" >0.26</td>\n",
    "      <td id=\"T_f4a83_row0_col2\" class=\"data row0 col2\" >0.25</td>\n",
    "      <td id=\"T_f4a83_row0_col3\" class=\"data row0 col3\" >0.26</td>\n",
    "      <td id=\"T_f4a83_row0_col4\" class=\"data row0 col4\" >0.25</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_f4a83_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
    "      <td id=\"T_f4a83_row1_col0\" class=\"data row1 col0\" >Logistic Regression</td>\n",
    "      <td id=\"T_f4a83_row1_col1\" class=\"data row1 col1\" >0.47</td>\n",
    "      <td id=\"T_f4a83_row1_col2\" class=\"data row1 col2\" >0.47</td>\n",
    "      <td id=\"T_f4a83_row1_col3\" class=\"data row1 col3\" >0.47</td>\n",
    "      <td id=\"T_f4a83_row1_col4\" class=\"data row1 col4\" >0.47</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_f4a83_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
    "      <td id=\"T_f4a83_row2_col0\" class=\"data row2 col0\" >K-Nearest Neighbors</td>\n",
    "      <td id=\"T_f4a83_row2_col1\" class=\"data row2 col1\" >0.36</td>\n",
    "      <td id=\"T_f4a83_row2_col2\" class=\"data row2 col2\" >0.4</td>\n",
    "      <td id=\"T_f4a83_row2_col3\" class=\"data row2 col3\" >0.36</td>\n",
    "      <td id=\"T_f4a83_row2_col4\" class=\"data row2 col4\" >0.35</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_f4a83_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
    "      <td id=\"T_f4a83_row3_col0\" class=\"data row3 col0\" >Decision Tree</td>\n",
    "      <td id=\"T_f4a83_row3_col1\" class=\"data row3 col1\" >0.22</td>\n",
    "      <td id=\"T_f4a83_row3_col2\" class=\"data row3 col2\" >0.24</td>\n",
    "      <td id=\"T_f4a83_row3_col3\" class=\"data row3 col3\" >0.22</td>\n",
    "      <td id=\"T_f4a83_row3_col4\" class=\"data row3 col4\" >0.16</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_f4a83_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
    "      <td id=\"T_f4a83_row4_col0\" class=\"data row4 col0\" >Random Forest</td>\n",
    "      <td id=\"T_f4a83_row4_col1\" class=\"data row4 col1\" >0.38</td>\n",
    "      <td id=\"T_f4a83_row4_col2\" class=\"data row4 col2\" >0.37</td>\n",
    "      <td id=\"T_f4a83_row4_col3\" class=\"data row4 col3\" >0.38</td>\n",
    "      <td id=\"T_f4a83_row4_col4\" class=\"data row4 col4\" >0.34</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_f4a83_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
    "      <td id=\"T_f4a83_row5_col0\" class=\"data row5 col0\" >Support Vector Machine</td>\n",
    "      <td id=\"T_f4a83_row5_col1\" class=\"data row5 col1\" >0.48</td>\n",
    "      <td id=\"T_f4a83_row5_col2\" class=\"data row5 col2\" >0.48</td>\n",
    "      <td id=\"T_f4a83_row5_col3\" class=\"data row5 col3\" >0.48</td>\n",
    "      <td id=\"T_f4a83_row5_col4\" class=\"data row5 col4\" >0.48</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_f4a83_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
    "      <td id=\"T_f4a83_row6_col0\" class=\"data row6 col0\" >Naive Bayes</td>\n",
    "      <td id=\"T_f4a83_row6_col1\" class=\"data row6 col1\" >0.45</td>\n",
    "      <td id=\"T_f4a83_row6_col2\" class=\"data row6 col2\" >0.47</td>\n",
    "      <td id=\"T_f4a83_row6_col3\" class=\"data row6 col3\" >0.45</td>\n",
    "      <td id=\"T_f4a83_row6_col4\" class=\"data row6 col4\" >0.45</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_f4a83_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
    "      <td id=\"T_f4a83_row7_col0\" class=\"data row7 col0\" >Stochastic Gradient Descent</td>\n",
    "      <td id=\"T_f4a83_row7_col1\" class=\"data row7 col1\" >0.46</td>\n",
    "      <td id=\"T_f4a83_row7_col2\" class=\"data row7 col2\" >0.46</td>\n",
    "      <td id=\"T_f4a83_row7_col3\" class=\"data row7 col3\" >0.46</td>\n",
    "      <td id=\"T_f4a83_row7_col4\" class=\"data row7 col4\" >0.45</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_f4a83_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
    "      <td id=\"T_f4a83_row8_col0\" class=\"data row8 col0\" >Gradient Boosting</td>\n",
    "      <td id=\"T_f4a83_row8_col1\" class=\"data row8 col1\" >0.44</td>\n",
    "      <td id=\"T_f4a83_row8_col2\" class=\"data row8 col2\" >0.44</td>\n",
    "      <td id=\"T_f4a83_row8_col3\" class=\"data row8 col3\" >0.44</td>\n",
    "      <td id=\"T_f4a83_row8_col4\" class=\"data row8 col4\" >0.43</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_f4a83_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
    "      <td id=\"T_f4a83_row9_col0\" class=\"data row9 col0\" >AdaBoost</td>\n",
    "      <td id=\"T_f4a83_row9_col1\" class=\"data row9 col1\" >0.35</td>\n",
    "      <td id=\"T_f4a83_row9_col2\" class=\"data row9 col2\" >0.36</td>\n",
    "      <td id=\"T_f4a83_row9_col3\" class=\"data row9 col3\" >0.35</td>\n",
    "      <td id=\"T_f4a83_row9_col4\" class=\"data row9 col4\" >0.35</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_f4a83_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
    "      <td id=\"T_f4a83_row10_col0\" class=\"data row10 col0\" >Quadratic Discriminant Analysis</td>\n",
    "      <td id=\"T_f4a83_row10_col1\" class=\"data row10 col1\" >0.17</td>\n",
    "      <td id=\"T_f4a83_row10_col2\" class=\"data row10 col2\" >0.2</td>\n",
    "      <td id=\"T_f4a83_row10_col3\" class=\"data row10 col3\" >0.17</td>\n",
    "      <td id=\"T_f4a83_row10_col4\" class=\"data row10 col4\" >0.15</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
