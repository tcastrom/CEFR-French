{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\castr\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>difficulty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le test de niveau en français est sur le site ...</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence difficulty\n",
       "id                                                              \n",
       "0   Les coûts kilométriques réels peuvent diverger...         C1\n",
       "1   Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
       "2   Le test de niveau en français est sur le site ...         A1\n",
       "3            Est-ce que ton mari est aussi de Boston?         A1\n",
       "4   Dans les écoles de commerce, dans les couloirs...         B1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence\n",
       "id                                                   \n",
       "0   Nous dûmes nous excuser des propos que nous eû...\n",
       "1   Vous ne pouvez pas savoir le plaisir que j'ai ...\n",
       "2   Et, paradoxalement, boire froid n'est pas la b...\n",
       "3   Ce n'est pas étonnant, car c'est une saison my...\n",
       "4   Le corps de Golo lui-même, d'une essence aussi..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the train data\n",
    "train = pd.read_csv('https://github.com/tcastrom/CEFR-French-/raw/main/Data/training_data.csv')\n",
    "train.set_index('id', inplace=True)\n",
    "display(train.head())\n",
    "\n",
    "#Import the unlabel data\n",
    "unlabel = pd.read_csv('https://github.com/tcastrom/CEFR-French-/raw/main/Data/unlabelled_test_data.csv')\n",
    "unlabel.set_index('id', inplace=True)\n",
    "display(unlabel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readability metrics in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import it and use it\n",
    "import textstat as txt\n",
    "# put it in french\n",
    "txt.set_lang('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>polysyllable_count</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
       "      <td>C1</td>\n",
       "      <td>43.31</td>\n",
       "      <td>9</td>\n",
       "      <td>15.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
       "      <td>A1</td>\n",
       "      <td>99.14</td>\n",
       "      <td>1</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le test de niveau en français est sur le site ...</td>\n",
       "      <td>A1</td>\n",
       "      <td>90.77</td>\n",
       "      <td>1</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
       "      <td>A1</td>\n",
       "      <td>95.84</td>\n",
       "      <td>0</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
       "      <td>B1</td>\n",
       "      <td>69.45</td>\n",
       "      <td>2</td>\n",
       "      <td>11.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence difficulty  \\\n",
       "id                                                                 \n",
       "0   Les coûts kilométriques réels peuvent diverger...         C1   \n",
       "1   Le bleu, c'est ma couleur préférée mais je n'a...         A1   \n",
       "2   Le test de niveau en français est sur le site ...         A1   \n",
       "3            Est-ce que ton mari est aussi de Boston?         A1   \n",
       "4   Dans les écoles de commerce, dans les couloirs...         B1   \n",
       "\n",
       "    flesch_reading_ease  polysyllable_count  coleman_liau_index  \n",
       "id                                                               \n",
       "0                 43.31                   9               15.39  \n",
       "1                 99.14                   1                4.57  \n",
       "2                 90.77                   1                5.03  \n",
       "3                 95.84                   0                2.86  \n",
       "4                 69.45                   2               11.79  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the flesh reading score for the training data \n",
    "train['flesch_reading_ease'] = train['sentence'].apply(txt.flesch_reading_ease)\n",
    "# Create the polysyllable count for the train data\n",
    "train['polysyllable_count'] = train['sentence'].apply(lambda x: txt.polysyllabcount(x))\n",
    "# Create the coleman liau index for the train data\n",
    "train['coleman_liau_index'] = train['sentence'].apply(txt.coleman_liau_index)\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readability metrics in unlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>polysyllable_count</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
       "      <td>86.45</td>\n",
       "      <td>2</td>\n",
       "      <td>10.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
       "      <td>89.75</td>\n",
       "      <td>1</td>\n",
       "      <td>8.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
       "      <td>80.11</td>\n",
       "      <td>1</td>\n",
       "      <td>10.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
       "      <td>94.83</td>\n",
       "      <td>1</td>\n",
       "      <td>9.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
       "      <td>8.80</td>\n",
       "      <td>12</td>\n",
       "      <td>14.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  flesch_reading_ease  \\\n",
       "id                                                                           \n",
       "0   Nous dûmes nous excuser des propos que nous eû...                86.45   \n",
       "1   Vous ne pouvez pas savoir le plaisir que j'ai ...                89.75   \n",
       "2   Et, paradoxalement, boire froid n'est pas la b...                80.11   \n",
       "3   Ce n'est pas étonnant, car c'est une saison my...                94.83   \n",
       "4   Le corps de Golo lui-même, d'une essence aussi...                 8.80   \n",
       "\n",
       "    polysyllable_count  coleman_liau_index  \n",
       "id                                          \n",
       "0                    2               10.24  \n",
       "1                    1                8.63  \n",
       "2                    1               10.58  \n",
       "3                    1                9.31  \n",
       "4                   12               14.30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the flesh reading score for the unlabel data\n",
    "unlabel['flesch_reading_ease'] = unlabel['sentence'].apply(txt.flesch_reading_ease)\n",
    "# Create the polysyllable count for the unlabel data\n",
    "unlabel['polysyllable_count'] = unlabel['sentence'].apply(lambda x: txt.polysyllabcount(x))\n",
    "# Create the coleman liau index for the unlabel data\n",
    "unlabel['coleman_liau_index'] = unlabel['sentence'].apply(txt.coleman_liau_index)\n",
    "display(unlabel.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Open Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ortho</th>\n",
       "      <th>phon</th>\n",
       "      <th>lemme</th>\n",
       "      <th>cgram</th>\n",
       "      <th>genre</th>\n",
       "      <th>nombre</th>\n",
       "      <th>freqlemfilms2</th>\n",
       "      <th>freqlemlivres</th>\n",
       "      <th>freqfilms2</th>\n",
       "      <th>freqlivres</th>\n",
       "      <th>...</th>\n",
       "      <th>orthrenv</th>\n",
       "      <th>phonrenv</th>\n",
       "      <th>orthosyll</th>\n",
       "      <th>cgramortho</th>\n",
       "      <th>deflem</th>\n",
       "      <th>defobs</th>\n",
       "      <th>old20</th>\n",
       "      <th>pld20</th>\n",
       "      <th>morphoder</th>\n",
       "      <th>nbmorph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NOM</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.36</td>\n",
       "      <td>58.65</td>\n",
       "      <td>81.36</td>\n",
       "      <td>58.65</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>avoir</td>\n",
       "      <td>AUX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18559.22</td>\n",
       "      <td>12800.81</td>\n",
       "      <td>6350.91</td>\n",
       "      <td>2926.69</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>avoir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>avoir</td>\n",
       "      <td>VER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13572.40</td>\n",
       "      <td>6426.49</td>\n",
       "      <td>5498.34</td>\n",
       "      <td>1669.39</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NOM,AUX,VER</td>\n",
       "      <td>93.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>avoir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a capella</td>\n",
       "      <td>akapEla</td>\n",
       "      <td>a capella</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>allepac a</td>\n",
       "      <td>alEpaka</td>\n",
       "      <td>a ca-pel-la</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.85</td>\n",
       "      <td>a-capella</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a cappella</td>\n",
       "      <td>akapEla</td>\n",
       "      <td>a cappella</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>alleppac a</td>\n",
       "      <td>alEpaka</td>\n",
       "      <td>a cap-pel-la</td>\n",
       "      <td>ADV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.85</td>\n",
       "      <td>a-cappella</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ortho     phon       lemme cgram genre nombre  freqlemfilms2  \\\n",
       "0           a        a           a   NOM     m    NaN          81.36   \n",
       "1           a        a       avoir   AUX   NaN    NaN       18559.22   \n",
       "2           a        a       avoir   VER   NaN    NaN       13572.40   \n",
       "3   a capella  akapEla   a capella   ADV   NaN    NaN           0.04   \n",
       "4  a cappella  akapEla  a cappella   ADV   NaN    NaN           0.04   \n",
       "\n",
       "   freqlemlivres  freqfilms2  freqlivres  ...    orthrenv  phonrenv  \\\n",
       "0          58.65       81.36       58.65  ...           a         a   \n",
       "1       12800.81     6350.91     2926.69  ...           a         a   \n",
       "2        6426.49     5498.34     1669.39  ...           a         a   \n",
       "3           0.07        0.04        0.07  ...   allepac a   alEpaka   \n",
       "4           0.07        0.04        0.07  ...  alleppac a   alEpaka   \n",
       "\n",
       "      orthosyll   cgramortho  deflem  defobs old20 pld20   morphoder  nbmorph  \n",
       "0             a  NOM,AUX,VER     NaN     NaN  1.00  1.00           a        1  \n",
       "1             a  NOM,AUX,VER     NaN     NaN  1.00  1.00       avoir        1  \n",
       "2             a  NOM,AUX,VER    93.0    16.0  1.00  1.00       avoir        1  \n",
       "3   a ca-pel-la          ADV     NaN     NaN  3.85  2.85   a-capella        2  \n",
       "4  a cap-pel-la          ADV     NaN     NaN  4.60  2.85  a-cappella        2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lexicon = pd.read_excel('https://github.com/tcastrom/CEFR-French-/raw/main/Data/Lexique382.xlsx')\n",
    "display(lexicon.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not interested in all the the columns here. Here are the columns we will retain and their meaning: \n",
    "\n",
    "- **Mot (ortho)**: La graphie est la forme orthographique du mot (p. ex.chienne) Attention, les mots correspondent\n",
    "seulement aux mots qui sont apparus au moins une fois dans notre corpus (16 + 50 millions de mots). Il peut\n",
    "ainsi y avoir des lemmes de certains mots apparus dans le corpus qui ne sont pas listés comme entrées\n",
    "indépendante car il n’y sont pas apparus en tant que tels (seul le mot dérivé était dans le corpus). Lexique 2\n",
    "comprenait 129 000 entrées tandis que Lexique 3 en comprenait 135 000 et Lexique 3.5 142 000- \n",
    "\n",
    "\n",
    "- **Fréquence du lemme par million selon le corpus de films (freqlemfilms2)** : Elle correspond à la somme des\n",
    "fréquences des formes fléchies de chaque lemme fournie par notre sélection de films. Ex: freq (arbre) = freq\n",
    "(\"arbre\") + freq (\"arbres\")\n",
    "\n",
    "- **Fréquence du lemme par million selon le corpus de livres (freqlemlivres)** : Elle correspond à la somme des\n",
    "fréquences des formes fléchies de chaque lemme fournie par notre sélection de livres de Frantext, normalisée par\n",
    "une division par 14,8 (le corpus original comprenant 14,7 millions d'occurrences).\n",
    "\n",
    "- **Fréquence par million selon le corpus de films (freqfilms2)** : Elle correspond à la fréquence par million\n",
    "d'occurrences du mot selon notre corpus de sous-titres. Contrairement à Lexique 2, danse aura deux entrées et\n",
    "deux fréquences, une pour sa forme nominale (p.ex. la danse) et une pour sa forme verbale (je danse). Attention,\n",
    "cette fréquence a changé à partir de Lexique 3.40.\n",
    "\n",
    "- **Fréquence par million selon le corpus de livres (freqlivres)** : Elle correspond à la fréquence par million\n",
    "d'occurrences du mot selon notre corpus de livres. (14,7 millions de mots).\n",
    "\n",
    "\n",
    "- **Nombre de lettres (nblettres)**\n",
    "\n",
    "-  **Nombre de syllabes (nbsyll)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ortho</th>\n",
       "      <th>freqlemfilms2</th>\n",
       "      <th>freqlemlivres</th>\n",
       "      <th>freqfilms2</th>\n",
       "      <th>freqlivres</th>\n",
       "      <th>nblettres</th>\n",
       "      <th>nbsyll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>81.36</td>\n",
       "      <td>58.65</td>\n",
       "      <td>81.36</td>\n",
       "      <td>58.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>18559.22</td>\n",
       "      <td>12800.81</td>\n",
       "      <td>6350.91</td>\n",
       "      <td>2926.69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>13572.40</td>\n",
       "      <td>6426.49</td>\n",
       "      <td>5498.34</td>\n",
       "      <td>1669.39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a capella</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a cappella</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ortho  freqlemfilms2  freqlemlivres  freqfilms2  freqlivres  \\\n",
       "0           a          81.36          58.65       81.36       58.65   \n",
       "1           a       18559.22       12800.81     6350.91     2926.69   \n",
       "2           a       13572.40        6426.49     5498.34     1669.39   \n",
       "3   a capella           0.04           0.07        0.04        0.07   \n",
       "4  a cappella           0.04           0.07        0.04        0.07   \n",
       "\n",
       "   nblettres  nbsyll  \n",
       "0          1       1  \n",
       "1          1       1  \n",
       "2          1       1  \n",
       "3          9       4  \n",
       "4         10       4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retain only the columns we need \n",
    "columns_needed = ['ortho', 'freqlemfilms2', 'freqlemlivres', 'freqfilms2', 'freqlivres', 'nblettres', 'nbsyll']\n",
    "lexicon = lexicon[columns_needed]\n",
    "\n",
    "display(lexicon.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ortho</th>\n",
       "      <th>freqlemfilms2</th>\n",
       "      <th>freqlemlivres</th>\n",
       "      <th>freqfilms2</th>\n",
       "      <th>freqlivres</th>\n",
       "      <th>nblettres</th>\n",
       "      <th>nbsyll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>18559.22</td>\n",
       "      <td>12800.81</td>\n",
       "      <td>6350.91</td>\n",
       "      <td>2926.69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a capella</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a cappella</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a contrario</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a fortiori</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.88</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142686</th>\n",
       "      <td>ôté</td>\n",
       "      <td>16.81</td>\n",
       "      <td>42.03</td>\n",
       "      <td>3.18</td>\n",
       "      <td>5.47</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142688</th>\n",
       "      <td>ôtée</td>\n",
       "      <td>16.81</td>\n",
       "      <td>42.03</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142690</th>\n",
       "      <td>ôtées</td>\n",
       "      <td>16.81</td>\n",
       "      <td>42.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142692</th>\n",
       "      <td>ôtés</td>\n",
       "      <td>16.81</td>\n",
       "      <td>42.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11.92</td>\n",
       "      <td>1.42</td>\n",
       "      <td>11.92</td>\n",
       "      <td>1.42</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125653 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ortho  freqlemfilms2  freqlemlivres  freqfilms2  freqlivres  \\\n",
       "1                 a       18559.22       12800.81     6350.91     2926.69   \n",
       "3         a capella           0.04           0.07        0.04        0.07   \n",
       "4        a cappella           0.04           0.07        0.04        0.07   \n",
       "5       a contrario           0.00           0.27        0.00        0.27   \n",
       "6        a fortiori           0.04           0.88        0.04        0.88   \n",
       "...             ...            ...            ...         ...         ...   \n",
       "142686          ôté          16.81          42.03        3.18        5.47   \n",
       "142688         ôtée          16.81          42.03        0.42        0.54   \n",
       "142690        ôtées          16.81          42.03        0.16        0.07   \n",
       "142692         ôtés          16.81          42.03        0.04        0.14   \n",
       "86569           NaN          11.92           1.42       11.92        1.42   \n",
       "\n",
       "        nblettres  nbsyll  \n",
       "1               1       1  \n",
       "3               9       4  \n",
       "4              10       4  \n",
       "5              11       4  \n",
       "6              10       4  \n",
       "...           ...     ...  \n",
       "142686          3       2  \n",
       "142688          4       2  \n",
       "142690          5       2  \n",
       "142692          4       2  \n",
       "86569           3       1  \n",
       "\n",
       "[125653 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique values in the ortho column is 125652\n",
      "The number of duplicate values in the ortho column is 1\n",
      "ortho            0.000796\n",
      "freqlemfilms2    0.000000\n",
      "freqlemlivres    0.000000\n",
      "freqfilms2       0.000000\n",
      "freqlivres       0.000000\n",
      "nblettres        0.000000\n",
      "nbsyll           0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# If a multiple lines have the same ortho, we will keep the ones that have a value in deflem and if there are multiple lines with the same ortho and have a deflem, we will keep the one with the highest freqfilms2\n",
    "# Sort by 'ortho' and 'freqlivres2' (highest first)\n",
    "lexicon = lexicon.sort_values(by=['ortho', 'freqlivres'], ascending=[True, False])\n",
    "\n",
    "# Drop duplicates, keeping the first (which has the highest 'freqlivres2')\n",
    "lexicon = lexicon.drop_duplicates(subset=['ortho'], keep='first')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "display(lexicon)\n",
    "\n",
    "# Display the number of unique and duplicate values in the 'ortho' column\n",
    "ortho_unique = lexicon['ortho'].nunique()\n",
    "ortho_duplicate = lexicon.shape[0] - ortho_unique\n",
    "print(f'The number of unique values in the ortho column is {ortho_unique}')\n",
    "print(f'The number of duplicate values in the ortho column is {ortho_duplicate}')\n",
    "\n",
    "# Display the percentage of missing values in the lexicon\n",
    "missing_values = lexicon.isnull().sum() / len(lexicon) * 100\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ortho            0.0\n",
      "freqlemfilms2    0.0\n",
      "freqlemlivres    0.0\n",
      "freqfilms2       0.0\n",
      "freqlivres       0.0\n",
      "nblettres        0.0\n",
      "nbsyll           0.0\n",
      "dtype: float64\n",
      "The number of lines in the lexicon is 125652\n",
      "The number of unique values in the ortho column is 125652\n",
      "The number of duplicate values in the ortho column is 0\n"
     ]
    }
   ],
   "source": [
    "# Drop all the lines with missing values\n",
    "lexicon = lexicon.dropna()\n",
    "\n",
    "# Display the percentage of missing values in the lexicon\n",
    "missing_values = lexicon.isnull().sum() / len(lexicon) * 100\n",
    "print(missing_values)\n",
    "\n",
    "# Display the number of lines \n",
    "print(f'The number of lines in the lexicon is {lexicon.shape[0]}')\n",
    "\n",
    "# Display the number of unique and duplicate values in the 'ortho' column\n",
    "ortho_unique = lexicon['ortho'].nunique()\n",
    "ortho_duplicate = lexicon.shape[0] - ortho_unique\n",
    "print(f'The number of unique values in the ortho column is {ortho_unique}')\n",
    "print(f'The number of duplicate values in the ortho column is {ortho_duplicate}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ortho</th>\n",
       "      <th>freqlemfilms2</th>\n",
       "      <th>freqlemlivres</th>\n",
       "      <th>freqfilms2</th>\n",
       "      <th>freqlivres</th>\n",
       "      <th>nblettres</th>\n",
       "      <th>nbsyll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>18559.22</td>\n",
       "      <td>12800.81</td>\n",
       "      <td>6350.91</td>\n",
       "      <td>2926.69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a capella</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a cappella</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a contrario</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a fortiori</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.88</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142685</th>\n",
       "      <td>ôtèrent</td>\n",
       "      <td>16.81</td>\n",
       "      <td>42.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142686</th>\n",
       "      <td>ôté</td>\n",
       "      <td>16.81</td>\n",
       "      <td>42.03</td>\n",
       "      <td>3.18</td>\n",
       "      <td>5.47</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142688</th>\n",
       "      <td>ôtée</td>\n",
       "      <td>16.81</td>\n",
       "      <td>42.03</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142690</th>\n",
       "      <td>ôtées</td>\n",
       "      <td>16.81</td>\n",
       "      <td>42.03</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.07</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142692</th>\n",
       "      <td>ôtés</td>\n",
       "      <td>16.81</td>\n",
       "      <td>42.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125652 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ortho  freqlemfilms2  freqlemlivres  freqfilms2  freqlivres  \\\n",
       "1                 a       18559.22       12800.81     6350.91     2926.69   \n",
       "3         a capella           0.04           0.07        0.04        0.07   \n",
       "4        a cappella           0.04           0.07        0.04        0.07   \n",
       "5       a contrario           0.00           0.27        0.00        0.27   \n",
       "6        a fortiori           0.04           0.88        0.04        0.88   \n",
       "...             ...            ...            ...         ...         ...   \n",
       "142685      ôtèrent          16.81          42.03        0.00        0.27   \n",
       "142686          ôté          16.81          42.03        3.18        5.47   \n",
       "142688         ôtée          16.81          42.03        0.42        0.54   \n",
       "142690        ôtées          16.81          42.03        0.16        0.07   \n",
       "142692         ôtés          16.81          42.03        0.04        0.14   \n",
       "\n",
       "        nblettres  nbsyll  \n",
       "1               1       1  \n",
       "3               9       4  \n",
       "4              10       4  \n",
       "5              11       4  \n",
       "6              10       4  \n",
       "...           ...     ...  \n",
       "142685          7       2  \n",
       "142686          3       2  \n",
       "142688          4       2  \n",
       "142690          5       2  \n",
       "142692          4       2  \n",
       "\n",
       "[125652 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average per sentence in Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to tokenize sentences into words\n",
    "def tokenize(sentence):\n",
    "    # Use regex to split on spaces, punctuation, and handle contractions\n",
    "    tokens = re.findall(r\"\\b\\w+\\b|[']\\w+\", sentence.lower())\n",
    "    return tokens\n",
    "\n",
    "# Step 2: Match these words with the lexicon dataset to retrieve their statistics\n",
    "# Creating a dictionary from the lexicon for quick lookup\n",
    "lexicon_dict = lexicon.set_index('ortho').T.to_dict()\n",
    "\n",
    "def get_lexicon_stats(word):\n",
    "    return lexicon_dict.get(word, {})\n",
    "\n",
    "# Step 3: Compute the required statistical measures for each lexicon measure\n",
    "def compute_statistics(words):\n",
    "    stats = {\n",
    "        'freqlemfilms2': [],\n",
    "        'freqlemlivres': [],\n",
    "        'freqfilms2': [],\n",
    "        'nblettres': [],\n",
    "        'nbsyll': [],\n",
    "    }\n",
    "    \n",
    "    for word in words:\n",
    "        word_stats = get_lexicon_stats(word)\n",
    "        for key in stats.keys():\n",
    "            if key in word_stats:\n",
    "                stats[key].append(word_stats[key])\n",
    "    \n",
    "    # Computing the required statistical measures\n",
    "    result = {}\n",
    "    for key, values in stats.items():\n",
    "        if values:  # Check if there are any values to compute statistics on\n",
    "            result[f'{key}_mean'] = np.mean(values)\n",
    "            result[f'{key}_median'] = np.median(values)\n",
    "            result[f'{key}_max'] = np.max(values)\n",
    "            result[f'{key}_min'] = np.min(values)\n",
    "            result[f'{key}_25%'] = np.percentile(values, 25)\n",
    "            result[f'{key}_75%'] = np.percentile(values, 75)\n",
    "        else:\n",
    "            result[f'{key}_mean'] = np.nan\n",
    "            result[f'{key}_median'] = np.nan\n",
    "            result[f'{key}_max'] = np.nan\n",
    "            result[f'{key}_min'] = np.nan\n",
    "            result[f'{key}_25%'] = np.nan\n",
    "            result[f'{key}_75%'] = np.nan\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>polysyllable_count</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>freqlemfilms2_mean</th>\n",
       "      <th>freqlemfilms2_median</th>\n",
       "      <th>freqlemfilms2_max</th>\n",
       "      <th>freqlemfilms2_min</th>\n",
       "      <th>freqlemfilms2_25%</th>\n",
       "      <th>...</th>\n",
       "      <th>nblettres_max</th>\n",
       "      <th>nblettres_min</th>\n",
       "      <th>nblettres_25%</th>\n",
       "      <th>nblettres_75%</th>\n",
       "      <th>nbsyll_mean</th>\n",
       "      <th>nbsyll_median</th>\n",
       "      <th>nbsyll_max</th>\n",
       "      <th>nbsyll_min</th>\n",
       "      <th>nbsyll_25%</th>\n",
       "      <th>nbsyll_75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
       "      <td>C1</td>\n",
       "      <td>43.31</td>\n",
       "      <td>9</td>\n",
       "      <td>15.39</td>\n",
       "      <td>5083.383947</td>\n",
       "      <td>86.650</td>\n",
       "      <td>25220.86</td>\n",
       "      <td>0.04</td>\n",
       "      <td>13.9300</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.763158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
       "      <td>A1</td>\n",
       "      <td>99.14</td>\n",
       "      <td>1</td>\n",
       "      <td>4.57</td>\n",
       "      <td>6604.464167</td>\n",
       "      <td>1214.575</td>\n",
       "      <td>25983.20</td>\n",
       "      <td>8.21</td>\n",
       "      <td>46.2975</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le test de niveau en français est sur le site ...</td>\n",
       "      <td>A1</td>\n",
       "      <td>90.77</td>\n",
       "      <td>1</td>\n",
       "      <td>5.03</td>\n",
       "      <td>9111.054615</td>\n",
       "      <td>2520.110</td>\n",
       "      <td>32236.50</td>\n",
       "      <td>5.61</td>\n",
       "      <td>50.7000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.307692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
       "      <td>A1</td>\n",
       "      <td>95.84</td>\n",
       "      <td>0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>11378.233333</td>\n",
       "      <td>4100.900</td>\n",
       "      <td>32236.50</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1402.3300</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
       "      <td>B1</td>\n",
       "      <td>69.45</td>\n",
       "      <td>2</td>\n",
       "      <td>11.79</td>\n",
       "      <td>6372.454516</td>\n",
       "      <td>1252.420</td>\n",
       "      <td>25220.86</td>\n",
       "      <td>2.02</td>\n",
       "      <td>54.6800</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.354839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence difficulty  \\\n",
       "0  Les coûts kilométriques réels peuvent diverger...         C1   \n",
       "1  Le bleu, c'est ma couleur préférée mais je n'a...         A1   \n",
       "2  Le test de niveau en français est sur le site ...         A1   \n",
       "3           Est-ce que ton mari est aussi de Boston?         A1   \n",
       "4  Dans les écoles de commerce, dans les couloirs...         B1   \n",
       "\n",
       "   flesch_reading_ease  polysyllable_count  coleman_liau_index  \\\n",
       "0                43.31                   9               15.39   \n",
       "1                99.14                   1                4.57   \n",
       "2                90.77                   1                5.03   \n",
       "3                95.84                   0                2.86   \n",
       "4                69.45                   2               11.79   \n",
       "\n",
       "   freqlemfilms2_mean  freqlemfilms2_median  freqlemfilms2_max  \\\n",
       "0         5083.383947                86.650           25220.86   \n",
       "1         6604.464167              1214.575           25983.20   \n",
       "2         9111.054615              2520.110           32236.50   \n",
       "3        11378.233333              4100.900           32236.50   \n",
       "4         6372.454516              1252.420           25220.86   \n",
       "\n",
       "   freqlemfilms2_min  freqlemfilms2_25%  ...  nblettres_max  nblettres_min  \\\n",
       "0               0.04            13.9300  ...           13.0            1.0   \n",
       "1               8.21            46.2975  ...            8.0            1.0   \n",
       "2               5.61            50.7000  ...            8.0            1.0   \n",
       "3               0.44          1402.3300  ...            6.0            2.0   \n",
       "4               2.02            54.6800  ...           11.0            1.0   \n",
       "\n",
       "   nblettres_25%  nblettres_75%  nbsyll_mean  nbsyll_median  nbsyll_max  \\\n",
       "0            2.0            7.0     1.763158            1.0         4.0   \n",
       "1            2.0            4.0     1.250000            1.0         3.0   \n",
       "2            2.0            4.0     1.307692            1.0         3.0   \n",
       "3            3.0            4.0     1.333333            1.0         2.0   \n",
       "4            2.0            6.0     1.354839            1.0         3.0   \n",
       "\n",
       "   nbsyll_min  nbsyll_25%  nbsyll_75%  \n",
       "0         1.0         1.0         2.0  \n",
       "1         1.0         1.0         1.0  \n",
       "2         1.0         1.0         1.0  \n",
       "3         1.0         1.0         2.0  \n",
       "4         1.0         1.0         2.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Break down each sentence into individual words using the tokenizer\n",
    "train['words'] = train['sentence'].apply(tokenize)\n",
    "\n",
    "# Applying the function to each row in the train dataset\n",
    "lexicon_measures = train['words'].apply(compute_statistics)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "lexicon_measures_df = pd.DataFrame(lexicon_measures.tolist())\n",
    "\n",
    "# Step 4: Add these computed measures as new columns to the train dataset\n",
    "train_concat = pd.concat([train, lexicon_measures_df], axis=1)\n",
    "\n",
    "# Drop the 'words' column as it is no longer needed\n",
    "train_concat = train_concat.drop(columns='words')\n",
    "\n",
    "# Display the updated train dataframe\n",
    "display(train_concat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values in the new columns\n",
    "missing_values = train_concat.isnull().sum()\n",
    "print(missing_values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average per Sentence unlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>polysyllable_count</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>freqlemfilms2_mean</th>\n",
       "      <th>freqlemfilms2_median</th>\n",
       "      <th>freqlemfilms2_max</th>\n",
       "      <th>freqlemfilms2_min</th>\n",
       "      <th>freqlemfilms2_25%</th>\n",
       "      <th>freqlemfilms2_75%</th>\n",
       "      <th>...</th>\n",
       "      <th>nblettres_max</th>\n",
       "      <th>nblettres_min</th>\n",
       "      <th>nblettres_25%</th>\n",
       "      <th>nblettres_75%</th>\n",
       "      <th>nbsyll_mean</th>\n",
       "      <th>nbsyll_median</th>\n",
       "      <th>nbsyll_max</th>\n",
       "      <th>nbsyll_min</th>\n",
       "      <th>nbsyll_25%</th>\n",
       "      <th>nbsyll_75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
       "      <td>86.45</td>\n",
       "      <td>2</td>\n",
       "      <td>10.24</td>\n",
       "      <td>4181.733000</td>\n",
       "      <td>4436.510</td>\n",
       "      <td>13572.40</td>\n",
       "      <td>24.99</td>\n",
       "      <td>1107.5350</td>\n",
       "      <td>4772.120</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
       "      <td>89.75</td>\n",
       "      <td>1</td>\n",
       "      <td>8.63</td>\n",
       "      <td>7940.903571</td>\n",
       "      <td>4308.805</td>\n",
       "      <td>25220.86</td>\n",
       "      <td>64.31</td>\n",
       "      <td>533.1575</td>\n",
       "      <td>13636.995</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Et, paradoxalement, boire froid n'est pas la b...</td>\n",
       "      <td>80.11</td>\n",
       "      <td>1</td>\n",
       "      <td>10.58</td>\n",
       "      <td>5342.156667</td>\n",
       "      <td>339.050</td>\n",
       "      <td>18188.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9.6700</td>\n",
       "      <td>12909.080</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ce n'est pas étonnant, car c'est une saison my...</td>\n",
       "      <td>94.83</td>\n",
       "      <td>1</td>\n",
       "      <td>9.31</td>\n",
       "      <td>3515.732222</td>\n",
       "      <td>31.950</td>\n",
       "      <td>18188.15</td>\n",
       "      <td>8.21</td>\n",
       "      <td>19.6100</td>\n",
       "      <td>5219.100</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Le corps de Golo lui-même, d'une essence aussi...</td>\n",
       "      <td>8.80</td>\n",
       "      <td>12</td>\n",
       "      <td>14.30</td>\n",
       "      <td>5236.215139</td>\n",
       "      <td>1174.325</td>\n",
       "      <td>32236.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>38.3100</td>\n",
       "      <td>5559.810</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>6.25</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  flesch_reading_ease  \\\n",
       "0  Nous dûmes nous excuser des propos que nous eû...                86.45   \n",
       "1  Vous ne pouvez pas savoir le plaisir que j'ai ...                89.75   \n",
       "2  Et, paradoxalement, boire froid n'est pas la b...                80.11   \n",
       "3  Ce n'est pas étonnant, car c'est une saison my...                94.83   \n",
       "4  Le corps de Golo lui-même, d'une essence aussi...                 8.80   \n",
       "\n",
       "   polysyllable_count  coleman_liau_index  freqlemfilms2_mean  \\\n",
       "0                   2               10.24         4181.733000   \n",
       "1                   1                8.63         7940.903571   \n",
       "2                   1               10.58         5342.156667   \n",
       "3                   1                9.31         3515.732222   \n",
       "4                  12               14.30         5236.215139   \n",
       "\n",
       "   freqlemfilms2_median  freqlemfilms2_max  freqlemfilms2_min  \\\n",
       "0              4436.510           13572.40              24.99   \n",
       "1              4308.805           25220.86              64.31   \n",
       "2               339.050           18188.15               0.22   \n",
       "3                31.950           18188.15               8.21   \n",
       "4              1174.325           32236.50               0.01   \n",
       "\n",
       "   freqlemfilms2_25%  freqlemfilms2_75%  ...  nblettres_max  nblettres_min  \\\n",
       "0          1107.5350           4772.120  ...            9.0            3.0   \n",
       "1           533.1575          13636.995  ...            8.0            1.0   \n",
       "2             9.6700          12909.080  ...           14.0            1.0   \n",
       "3            19.6100           5219.100  ...           11.0            1.0   \n",
       "4            38.3100           5559.810  ...           14.0            1.0   \n",
       "\n",
       "   nblettres_25%  nblettres_75%  nbsyll_mean  nbsyll_median  nbsyll_max  \\\n",
       "0           4.00           5.75     1.500000            1.0         3.0   \n",
       "1           2.25           6.00     1.428571            1.0         3.0   \n",
       "2           2.00           5.00     1.666667            1.0         6.0   \n",
       "3           2.00           6.00     1.555556            1.0         3.0   \n",
       "4           2.00           6.25     1.555556            1.0         5.0   \n",
       "\n",
       "   nbsyll_min  nbsyll_25%  nbsyll_75%  \n",
       "0         1.0         1.0        1.75  \n",
       "1         1.0         1.0        2.00  \n",
       "2         1.0         1.0        1.00  \n",
       "3         1.0         1.0        2.00  \n",
       "4         1.0         1.0        2.00  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Break down each sentence into individual words using the tokenizer\n",
    "unlabel['words'] = unlabel['sentence'].apply(tokenize)\n",
    "\n",
    "# Applying the function to each row in the unlabel dataset\n",
    "lexicon_measures = unlabel['words'].apply(compute_statistics)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "lexicon_measures_df = pd.DataFrame(lexicon_measures.tolist())\n",
    "\n",
    "# Step 4: Add these computed measures as new columns to the unlabel dataset\n",
    "unlabel_concat = pd.concat([unlabel, lexicon_measures_df], axis=1)\n",
    "\n",
    "# Drop the 'words' column as it is no longer needed\n",
    "unlabel_concat = unlabel_concat.drop(columns='words')\n",
    "\n",
    "# Display the updated unlabel dataframe\n",
    "display(unlabel_concat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values in the new columns\n",
    "missing_values = unlabel_concat.isnull().sum()\n",
    "print(missing_values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the index column 'id'\n",
    "train_concat.index.name = 'id'\n",
    "unlabel_concat.index.name = 'id'\n",
    "\n",
    "# Drop the column sentence\n",
    "train_concat = train_concat.drop(columns='sentence')\n",
    "unlabel_concat = unlabel_concat.drop(columns='sentence')\n",
    "\n",
    "# Save the train_concat and unlabel_concat dataframes to CSV files\n",
    "train_concat.to_csv('train_metrics_only.csv')\n",
    "unlabel_concat.to_csv('unlabel_metrics_only.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
